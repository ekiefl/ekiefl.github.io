---
layout: post
title: "Building a neural network from scratch"
categories: [miscellaneous]
excerpt: "Creating neural net and watching it learn"
comments: true
authors: [evan]
image:
  feature: pooltool/pooltool_banner.png
  display: false
---

{% capture images %}{{site.url}}/images/miscellaneous/slownet{% endcapture %}
{% include _toc.html %}

## Motivation

There are lots of amazing Python libraries for deep learning (PyTorch, Keras, Tensorflow, etc) that allow practitioners to get their hands dirty with building, training, and predicting with deep neural nets. These libraries are so well built that one can utilize them (to some degree of success) **without understanding what's going on under the hood**.

I don't want to be that person, so after taking Andrew Ng's "Neural Networks and Deep Learning" course, I figured the best way to solidify the knowledge was to build a neural network from scratch using base python.

In this post I'm going to build a python library for creating neural nets called `slownet`, train a neural net on the MNIST postal service data using gradient descent, and visualize an animation of how the neural net learns.

Why is it called `slownet`? My goal is to implement an object-oriented design expresses the inner-workings of neural network computations transparently. This means no vectorization or matrix math and plenty of for loops. To reiterate, **the goal is not to be computationally efficient, it is to be computationally transparent**. To further drive home this point, the name of the library is going to be aptly named `slownet`.

## Hierarchical components of a neural net

I started how I start all my projects, with a [github repo](https://github.com/ekiefl/slownet) and a directory structure that looks like this:

```
./
├── slownet/
│   ├── objects.py
│   └── __init__.py
├── README.md
└── LICENSE
```

My first task was to create the hierarchy of classes I would use for structuring neural nets (NNs). NNs are composed of layers which are composed of neurons, and neurons are connected to each other with weights. So I decided each of these concepts would require its own class, which I defined all of in `slownet/objects.py`.

Starting from the top, I created a `Net` class.

```python
class Net(object):
    def __init__(self):
        self.layers = {}

    def attach_layer(self, layer):
        self.layers[layer.id] = layer

def is_layer(layer):
    if not isinstance(layer, Layer):
        raise Exception("layer must be of type Layer")
```

`Net` is a simple class with an attribute called `layers` and a method called `attach_layer`. To attach a layer to, one can call `attach_layer`, which makes sure what is being passed is indeed a layer, and then adds the layer to the `layers` dictionary.

Continuing down the hierarchy, here is the `Layer` class I wrote:

```python
class Layer(object):
    def __init__(self, layer_id, attach_to):
        self.id = layer_id
        self.neurons = {}
        self.attach_to_net(attach_to)


    def attach_neuron(self, neuron):
        is_neuron(neuron)
        self.neurons[neuron.id] = neuron


    def attach_to_net(self, net):
        is_net(net)
        self.net = net
        self.net.attach_layer(self)
```

`Layer` objects can house `Neuron` objects in a dictionary called `neurons` by calling `attach_neuron`, which follows the same logical flow as `Net.attach_layer`. Initializing a `Layer` object requires you to attach it to a `Net` object, which you could do like so:

```python
In [1]: from slownet.objects import Net, Layer
   ...: net = Net()
   ...: Layer(0, attach_to=net)
   ...: net.layers
Out[1]: {0: <slownet.objects.Layer at 0x137b10358>}
```

Moving further down the chain, we get to the `Neuron` class:

```python
class Neuron(object):
    def __init__(self, neuron_id, attach_to, value=0):
        self.value = value
        self.id = neuron_id

        self.attach_to_layer(attach_to)

        self.weights = {
            'in': {},
            'out': {},
        }


    def attach_to_layer(self, layer):
        is_layer(layer)
        self.layer = layer
        self.layer.attach_neuron(self)


    def attach_weight(self, weight, direction):
        is_weight(weight)

        if direction not in ('in', 'out'):
            raise ValueError(f"Neuron.add_weight :: direction must be 'in' or 'out'")

        self.weights[direction][weight.id] = weight
```

`Neuron` house its activation value (`value`) as well as a dictionary of all incoming and outgoing weights that connect to it. Weights can be attached to a `Neuron` via `attach_weight`, and it can be specified with the parameter `direction` as to whether the neuron sends (`out`) or receives (`in`) the weight.

And finally, at the bottom of the totem pole, is the `Weight` class.

```python
class Weight(object):
    def __init__(self, weight_id, incoming_neuron, outgoing_neuron, value=0):
        self.id = weight_id
        self.value = value
        self.has_incoming = False
        self.has_outgoing = False

        self.attach_to_incoming(incoming_neuron)
        self.attach_to_outgoing(outgoing_neuron)


    def attach_to_incoming(self, neuron):
        is_neuron(neuron)
        self.incoming = neuron
        self.incoming.attach_weight(self, 'in')
        self.has_incoming = True


    def attach_to_outgoing(self, neuron):
        is_neuron(neuron)
        self.outgoing = neuron
        self.outgoing.attach_weight(self, 'out')
        self.has_outgoing = True
```

`Weight` stores its value as `value`, the neuron it comes from as `outgoing`, and the neuron it goes to as `incoming`.

I added all of these classes to `slownet.objects` in [the first commit](https://github.com/ekiefl/slownet/commit/8f1055d4504d89d29e3911b12dd1ffef2a2aa44e) and called it a day.

## Constructing a neural net

- talk about Builder
- test it out
- visualize
