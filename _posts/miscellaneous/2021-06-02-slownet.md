---
layout: post
title: "Building a neural network from scratch"
categories: [miscellaneous]
excerpt: "Creating neural net and watching it learn"
comments: true
authors: [evan]
image:
  feature: pooltool/pooltool_banner.png
  display: false
---

{% capture images %}{{site.url}}/images/miscellaneous/slownet{% endcapture %}
{% include _toc.html %}

## Motivation

There are lots of amazing Python libraries for deep learning (PyTorch, Keras, Tensorflow, etc) that allow practitioners to get their hands dirty with building, training, and predicting with deep neural nets. These libraries are so well built that one can utilize them (to some degree of success) **without understanding what's going on under the hood**.

I don't want to be that person, so after taking Andrew Ng's "Neural Networks and Deep Learning" course, I figured one fun way to prove to myself that I understand how neural networks work was to build a neural network from scratch using base python.

In this post I'm going to build a python library for creating neural nets called `slownet`, train a neural net on the MNIST postal service data using gradient descent, and visualize an animation of how the neural net learns.

Why is it called `slownet`? My goal is to implement an object-oriented design that expresses the inner-workings of neural network computations transparently and prioritizes introspection of individual weights, biases, activations, etc for visualization purposes. This means no vectorization or matrix math and plenty of for loops. To reiterate, **the goal is not to be computationally efficient, it is to be computationally transparent**. To further drive home this point, the name of the library is going to be aptly named `slownet`.

## Hierarchical components of a neural net

I started how I start all my projects, with a [github repo](https://github.com/ekiefl/slownet) and a directory structure that looks like this:

```
./
├── slownet/
│   ├── objects.py
│   └── __init__.py
├── README.md
└── LICENSE
```

My first task was to create the hierarchy of classes I would use for structuring neural nets (NNs). NNs are composed of layers which are composed of neurons, and neurons are connected to each other with weights. So I decided each of these concepts would require its own class, which I defined all of in `slownet/objects.py`.

Starting from the top, I created a `Net` class.

```python
class Net(object):
    def __init__(self):
        self.layers = {}

    def attach_layer(self, layer):
        self.layers[layer.id] = layer

def is_layer(layer):
    if not isinstance(layer, Layer):
        raise Exception("layer must be of type Layer")
```

`Net` is a simple class with an attribute called `layers` and a method called `attach_layer`. To attach a layer to, one can call `attach_layer`, which makes sure what is being passed is indeed a layer, and then adds the layer to the `layers` dictionary.

Continuing down the hierarchy, here is the `Layer` class I wrote:

```python
class Layer(object):
    def __init__(self, layer_id, attach_to):
        self.id = layer_id
        self.neurons = {}
        self.attach_to_net(attach_to)


    def attach_neuron(self, neuron):
        is_neuron(neuron)
        self.neurons[neuron.id] = neuron


    def attach_to_net(self, net):
        is_net(net)
        self.net = net
        self.net.attach_layer(self)
```

`Layer` objects can house `Neuron` objects in a dictionary called `neurons` by calling `attach_neuron`, which follows the same logical flow as `Net.attach_layer`. Initializing a `Layer` object requires you to attach it to a `Net` object, which you could do like so:

```python
In [1]: from slownet.objects import Net, Layer
   ...: net = Net()
   ...: Layer(0, attach_to=net)
   ...: net.layers
Out[1]: {0: <slownet.objects.Layer at 0x137b10358>}
```

Moving further down the chain, we get to the `Neuron` class:

```python
class Neuron(object):
    def __init__(self, neuron_id, attach_to, value=0):
        self.value = value
        self.id = neuron_id

        self.attach_to_layer(attach_to)

        self.weights = {
            'in': {},
            'out': {},
        }


    def attach_to_layer(self, layer):
        is_layer(layer)
        self.layer = layer
        self.layer.attach_neuron(self)


    def attach_weight(self, weight, direction):
        is_weight(weight)

        if direction not in ('in', 'out'):
            raise ValueError(f"Neuron.add_weight :: direction must be 'in' or 'out'")

        self.weights[direction][weight.id] = weight
```

`Neuron` house its activation value (`value`) as well as a dictionary of all incoming and outgoing weights that connect to it. Weights can be attached to a `Neuron` via `attach_weight`, and it can be specified with the parameter `direction` as to whether the neuron sends (`out`) or receives (`in`) the weight.

And finally, at the bottom of the totem pole, is the `Weight` class.

```python
class Weight(object):
    def __init__(self, weight_id, incoming_neuron, outgoing_neuron, value=0):
        self.id = weight_id
        self.value = value
        self.has_incoming = False
        self.has_outgoing = False

        self.attach_to_incoming(incoming_neuron)
        self.attach_to_outgoing(outgoing_neuron)


    def attach_to_incoming(self, neuron):
        is_neuron(neuron)
        self.incoming = neuron
        self.incoming.attach_weight(self, 'in')
        self.has_incoming = True


    def attach_to_outgoing(self, neuron):
        is_neuron(neuron)
        self.outgoing = neuron
        self.outgoing.attach_weight(self, 'out')
        self.has_outgoing = True
```

`Weight` stores its value as `value`, the neuron it comes from as `outgoing`, and the neuron it goes to as `incoming`.

I added all of these classes to `slownet.objects` in [the first commit](https://github.com/ekiefl/slownet/commit/8f1055d4504d89d29e3911b12dd1ffef2a2aa44e) and called it a day.

## Constructing a neural net

Next, I created a factory class that builds NNs from the objects defined above.

```python
class NetFactory(object):
    def __init__(self, layer_dims):
        self.layer_dims = layer_dims
        self.num_layers = len(layer_dims)


    def new(self):
        net = Net()

        # Create layers and neurons
        for layer_id, layer_dim in enumerate(self.layer_dims):
            layer = Layer(layer_id)
            layer.attach_to_net(net)

            for neuron_id in range(layer_dim):
                neuron = Neuron(neuron_id=neuron_id)
                neuron.attach_to_layer(layer)

        # Connect adjacent layers with weights
        for l in range(0, self.num_layers-1):
            self.connect_layers(net.layers[l], net.layers[l+1])

        return net


    def connect_layers(self, layer1, layer2):
        for i, neuron1 in layer1.neurons.items():
            for j, neuron2 in layer2.neurons.items():
                weight = Weight((i,j))
                weight.attach_to_outgoing(neuron1)
                weight.attach_to_incoming(neuron2)
```
[[Browse commit]](https://github.com/ekiefl/slownet/commit/b7a0c0d457a2ebfcd04011a610baa7fd9cca261a)

Here is how `NetFactory` can be used.

```python
In [1]: import slownet.objects as objects
   ...: net = objects.NetFactory(layer_dims=[3,4,6]).new()
```

The only input is a list called `layer_dims` that specifies the number of layers, and the number of neurons in each layer. Above, `layer_dims = [3,4,6]` is passed which specifies a NN with 3 layers, where the first layer has 3 neurons, the second 4, and the third 6.

The NN components can be queried hierarchically like so:

```python
In [2]: net.layers
Out[2]:
{0: <slownet.objects.Layer at 0x11dc388e0>,
 1: <slownet.objects.Layer at 0x11dc38760>,
 2: <slownet.objects.Layer at 0x11de8f7c0>}
```

```python
In [3]: net.layers[0].neurons
Out[3]:
{0: <slownet.objects.Neuron at 0x11dc38ee0>,
 1: <slownet.objects.Neuron at 0x11de8fdf0>,
 2: <slownet.objects.Neuron at 0x11de8fe80>}
```

```python
In [4]: net.layers[0].neurons[0].weights
Out[4]:
{'in': {},
 'out': {(0, 0): <slownet.objects.Weight at 0x11dc38eb0>,
  (0, 1): <slownet.objects.Weight at 0x11de8fa90>,
  (0, 2): <slownet.objects.Weight at 0x11de8f610>,
  (0, 3): <slownet.objects.Weight at 0x11de8fb20>}}
```

Great! Now I have a way to generate NNs of a specific shape.

## Visualizing the neural net

I wanted to visualize neural nets made with `NetFactory` and decided Plotly would be a good tool for the job. I've used Plotly previously to visualize [patterns of dog behavior]({{ site.url }}/2021/03/14/maple-classifier/), and I really liked the results.

Since this marks my departure from the standard library, I first added a `requirements.txt` to the project and added conda install instructions to the `README` (commit is [here](https://github.com/ekiefl/slownet/commit/5da88c9b1b10dc782061c37ff1244857df489c17)). Then, I got to work on a visualization scheme.






