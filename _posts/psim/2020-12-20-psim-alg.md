---
layout: post
title: "Creating a billiards simulator II: Algorithm theory"
categories: [psim]
excerpt: "A dive into the algorithmic theory behind pool simulation"
comments: true
authors: [evan]
image:
  feature: psim/psim_banner.png
  display: true
---

{% capture images %}{{site.url}}/images/psim/psim-alg{% endcapture %}
{% include _toc.html %}

## What is a pool simulator?

In the [last post]({{ site.url }}/2020/04/24/psim-theory/) I discussed the physics for all the different phenomena in pool and
outlined equations of motion for each scenario. Yet there is still a critical missing piece: how and
when should these equations be applied? For instance, I have equations to resolve the collision
between two balls, but how do I know which two balls collided and when?

A pool simulator is more than just a sum of physics equations. Critically, a pool simulator requires
an algorithm that coordinates the proper usage of these equations, and glues them together to evolve
a shot from the moment the cue ball is struck to the moment the last ball stops moving. This
algorithm is what I call the **evolution algorithm**. The evolution algorithm advances the **system
state** from some initial time $t_i$, to some final time $t_f$.

In this post I define the system state, and then discuss two evolution algorithms: (1) discrete time
evolution, and (2) continuous event-based evolution.

## What is the system state?

In the [last post]({{ site.url }}/2020/04/24/psim-theory/) I defined the ball state by 3 vectors:
the ball's displacement $\vec{r}(t)$, velocity $\vec{v}(t)$, and angular velocity $\vec{\omega}(t)$.
Together, these three vectors fully characterize the state of a ball at any given time $t$. Since a
pool simulation has multiple balls, a state needs to be defined for the entire system, _i.e._ the
system state. Since the table is assumed to be fixed and unchanging, the system state for a given
time $t$ is just the collection of individual ball states at that time $t$.

<div class="extra-info" markdown="1">
<span class="extra-info-header">Definition: system state</span>

Mathematically, the ball state for the $i$th ball is

$$
s_i(t) = \{ \vec{r}_i(t) \, , \vec{v}_i(t), \, \vec{\omega}_i(t) \}
\notag
$$

where $\vec{r}_i(t)$ is the ball's position, $\vec{v}_i(t)$ is the ball's velocity, and
$\vec{\omega}_i(t)$ is the ball's angular velocity. The system state for a table with $N$ balls is
then

$$
S(t) = \{ s_i(t) \, \, \forall i \in \{1, ..., N\} \}
\notag
$$

where $t$ is some arbitrary time.

</div>

The evolution algorithm calculates the system system for a desired $t$ based on the system state at
an earlier time. With this definition formalized, let's move on to discuss the first evolution
algorithm: discrete time evolution.

## Discrete time evolution

The premise of discrete time evolution is to slowly advance the system state in very small
discrete steps of time. After each timestep events can be detected and resolved. Did a ball collide
with another ball, or with a cushion? If so, resolve the ball states, then advance to the next
system state. This is a really straight-forward evolution algorithm that is very convenient, and
simple to understand. Unfortunately, discrete time evolution introduces intrinsic error that reduces accuracy of when
events occur. An example is outlined in Figure 1.

[![discrete_error]({{images}}/discrete_error.jpg)]({{images}}/discrete_error.jpg){:.center-img .width-90}
_**Figure 1**. Collision detection using discrete time evolution. The collision is detected at the
timestep when the 2 balls overlap slightly._

In the above scenario, the blue ball gets incrementally closer to the red ball with each
timestep. After the third time step, the blue and red balls overlap slightly, triggering the detection
of a collision. Herein lies the fundamental problem with discrete time evolution: collision events
are never predicted, by rather detected _after_ they were already supposed to have happened.
So in the above example, the calculated collision time is $3 \Delta t$, even though the actual
collision time is less than that--more like $2.8 \Delta t$.

The inaccuracy introduced by discrete time evolution can always be ameliorated by making $\Delta
t$ smaller and smaller, yet there will always exist a margin of error on the order of $\Delta t$.
Furthermore, decreasing $\Delta t$ comes at massive computational cost. For example if you decrease
the timestep 100-fold--sure, you increase the accuracy 100-fold--but you also increase the
computational complexity 100-fold, since now you've gotta step through 100 times more time steps.

This can become brutal when dealing with pool simulations. Ball speeds commonly
reach $10$ m/s, and a reasonable requirement for realism is that 2 balls should never intersect more
than $1/100$th of a ball radius ($0.3$ mm). The required timestep for this level of realism is then
$30$ microseconds. If the time from the cue strike to the last ball rolling is 10 seconds, that is
$30,000$ time steps in total for one shot. If the level of realism is $1/1000$th a ball radius, that
is $300,000$ time steps. Yikes.

The problem with this is all of the wasted computation... I don't need $30$ microsecond time steps
when all of the balls are far apart and barely moving. It is only really in select scenarios, such
as a pool break, that realism demands such miniscule time steps. So a smart discrete time
evolution scheme would be to cut down on the number of time steps by making them
[adaptive](https://en.wikipedia.org/wiki/Adaptive_step_size) depending on the state of the system.
There are an infinite number of ways you could develop heuristics for an adaptive time stepper, that
may be based on the distances between balls (if they are far apart, increase the time step), or
based on velocities (if they are moving fast, decrease the time step). I'm not even going to go
there because the possibilities are endless, although I am convinced that if Virtual Pool 4 or
ShootersPool are using discrete time evolution, they are using adaptive time stepping.

<div class="extra-info" markdown="1">
<span class="extra-info-header">Aside: sometimes, you have to use discrete time evolution</span>

Discrete time evolution is sometimes a necessary evil in many-body systems when equations of
motion cannot be solved analytically. For example, the [three-body
problem](https://en.wikipedia.org/wiki/Three-body_problem) (3 planets exhibiting gravitational
forces on one another) has no analytical formulae that express the positions of the planets as a
function of time. That's because the system is just so complex:

[![3_body_problem]({{images}}/3_body_problem.gif)]({{images}}/3_body_problem.gif){:.center-img .width-90}
*Trajectories for three planetary bodies exhibiting gravitational forces on one another must be found through
discrete time evolution, since no analytical solutions exist. [Source](https://en.wikipedia.org/wiki/Three-body_problem)*

Fortunately, for any given state of the system, the _forces_ governing the equations are calculable
(inverse square law), and this is _all_ that is needed for discrete time evolution. If $\Delta t$
is chosen to be small enough, one can consider the force between the $i$th and $(i+1)$th time step
to be constant and since $\vec{F}=m\vec{a}$, that means acceleration is constant. We can discretely integrate
this equation once and then again to yield how the velocity and position should be updated for the $(i+1)$th timestep:

$$
\vec{a}_{i+1} = \vec{F}/m
\notag
$$

$$
\vec{v}_{i+1} = (\vec{F}/m) t + \vec{v}_i
\notag
$$

$$
\vec{r}_{i+1} = \frac{(\vec{F}/m)}{2}t^2 + \vec{v}_{i+1} t + \vec{r}_i
\notag
$$

</div>

## Continuous event-based evolution

{:.notice}
The continuous event-based evolution algorithm was first developed by Leckie and Greenspan in a
seminal paper entitled [An Event-Based Pool Physics
Simulator](https://link.springer.com/chapter/10.1007/11922155_19). If you would like to hear it
straight from the horse's mouth, a free pre-print of this publication is available
[here](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.89.4627&rep=rep1&type=pdf).

In the [last post]({{ site.url }}/2020/04/24/psim-theory/) I presented a bunch of analytical
equations of motion for ball trajectories, depending on whether the ball is [stationary]({{ site.url
}}/2020/04/24/psim-theory/#--case-1-stationary), [spinning]({{ site.url
}}/2020/04/24/psim-theory/#--case-2-spinning), [rolling]({{ site.url
}}/2020/04/24/psim-theory/#--case-3-rolling), [sliding]({{ site.url
}}/2020/04/24/psim-theory/#--case-4-sliding), or [airborne]({{ site.url
}}/2020/04/24/psim-theory/#section-iv-ball-air-interactions).

These equations are perfect, because we can use them to evolve the ball states to any arbitrary
time. The only (vital) problem is that **events** such as the collision in Figure 1 disrupt their
validity, since they are developed assuming the ball acts in isolation. For example, a ball
rolling with a very high velocity may be destined to travel 50m in an isolated environment, yet
collides with a cushion after just a few meters. Thus, **the system can safely be evolved via [the
rolling equations of motion]({{ site.url }}/2020/04/24/psim-theory/#--case-3-rolling) up until the
moment of collision**, at which point the event must be resolved via [the ball-cushion interaction
equations]({{ site.url }}/2020/04/24/psim-theory/#section-iii-ball-cushion-interactions). After the
collision is resolved, the system can be evolved up until the next event.

This prescription of evolving the equations of motion up until the next event forms the basis of
the continuous event-based evolution algorithm. Simply stated, the algorithm goes like this:

<div class="extra-info" markdown="1">
<span class="extra-info-header">Continuous event-based evolution algorithm</span>

1. Set $t \rightarrow 0$.
2. Calculate the time $\Delta t_E$ until the next event. If $\Delta t_E = \infty$, stop.
3. Evolve the system state $S(t) \rightarrow S(t + \Delta t_E)$.
4. Resolve the event.
5. Set $t \rightarrow t + \Delta t_E$.
5. Repeat steps 2-5.

</div>

Let's walk through a loop of the algorithm. Assume the time is currently $t$, such that the system
state is $S(t)$.

The first step is determining when the next event occurs. By next event, I mean that **no other
event precedes it**. Assume this occcurs an amount of time $\Delta t_E$ from the current time.
Calculating $\Delta t_E$ is non-trivial, and my guess is that around 95% of the algorithm's
computational complexity is allocated to this specific task. The intricacies of this process will be
described _ad nauseam_ in the next section, but until then, assume $\Delta t_E$ is calculable.

Once calculated, the next step is to advance the system state from $S(t)$ to $S(t + \Delta t_E)$.
This means updating each ball's state to $s_i(\tau + \Delta t_E)$, where the equations of motion are
determined depending on whether the ball is stationary, spinning, rolling, sliding, or airborne.
Every ball is updated an amount $\Delta t_E$, independent of whether they are involved in the event
or not.

Then, the states of any balls involved in the event must be resolved. Some examples: If the event is
two balls colliding, their states are are resolved via [the ball-ball interaction equations]({{
site.url }}/2020/04/24/psim-theory/#section-ii-ball-ball-interactions). If the event is a ball
contacting a rail, its state is resolved via [the ball-cushion interaction equations]({{ site.url
}}/2020/04/24/psim-theory/#section-iii-ball-rail-interactions). If the event is a ball transitioning
from sliding to rolling, its state is resolved by updating its equations of motions from
[sliding]({{ site.url }}/2020/04/24/psim-theory/#--case-4-sliding) to [rolling]({{ site.url
}}/2020/04/24/psim-theory/#--case-3-rolling).

Once the states of the balls involved in the event have been solved, every ball now has equations of
motion that will be valid until the next event occurs. Thus, the process repeats itself.

So that's how the algorithm works, and it is superior to the discrete time evolution algorithm
because one can advance directly to the next event. Of course, this algorithm is utterly useless if
we can't calculate $\Delta t_E$, the time until the next event. To do so, we first need to formally
define what an event is and characterize the extent of possible events.

### Events

In the context of the continuous event-based evolution algorithm, an event is defined as anything
that invalidates the equations of motion for 1 or more balls, due to something that is unaccounted
for in the equations of motion, such as a collision with another ball. In general, events are either
collisions or transitions. The 3 modelled collisions are:

1. ball-ball collision
2. ball-cushion collision
3. ball-slate collision

The ball-ball collision involves 2 balls, one of which must be in a translating motion state:
rolling, sliding, or airborne. The other ball may be in any motion state: stationary, spinning,
rolling, sliding or airborne.

{% assign network_path = images | append: '/ball_ball_network.json' %}
{% include _network.html path=network_path id="ball_ball_network" height=200 %}

_Figure 2. How the ball-ball collision affects ball motion states._

{% assign network_path = images | append: '/ball_ball_event_path.json' %}
{% include _network.html path=network_path id="ball_ball_event_path" height=200 %}

If the incoming motion state is not airborne, then neither will be the outgoing state. Conversely,
if the incoming motion state is airborne, so will be the outgoing motion state. In other words, a
table-bound ball cannot become airborne due to a ball-ball collision. I admit this might be
confusing if you imagine what happens when an airborne ball collides with a ball on the table. Since
the line of centers between the two balls is directed _into_ the table, the outgoing velocity of the
table-bound ball has a component into the table, which initiates a ball-slate collision. The result
of this is that the table-bound ball becomes airborne. In the continuous event-based algorithm I've
developed, the ball becomes airborne after the ball-slate collision, not the ball-ball collision,
which are separated by an infinitesimally small time later. The totality of this process looks like
this:












=========================================

5. spinning-stationary transition
7. rolling-stationary transition
8. rolling-spinning transition
10. sliding-stationary transition (rare)
11. sliding-spinning transition (rare)
12. sliding-rolling transition

You'll notice there are two types of events: collisions and transitions. Only transitions that occur
independent of a collision are shown. For example, a stationary ball undergoes a stationary-sliding
transition when a moving ball collides into it. However, this transition occurs as a result of
resolving the ball-ball collision event, and does not need to be a separate event. Since this is the
only way a ball can transition from stationary to sliding, it is excluded in this list. On the other
hand, a rolling ball will naturally undergo a rolling-stationary transition when it runs out of
steam, and this occurs independent of other events. Therefore it is included in this list and
considered its own event.

To visualize the ways in which events alter the ball motion states, I visualized the event-state
relationship as an interactive network:


Note that not every path of this network is physical. For example, a ball cannot transition directly
from rolling to airborne via the ball-cushion collision event (though it can transition from rolling
to sliding via the ball-cushion collision, then an infinitesimal time later from sliding to airborne
via the ball-slate collision).

### Algorithm description


### List of events





which
assume the ball is in isolation and won't interact with a rail, ball, or anything else besides the
cloth. These equations therefore only remain valid until such an event occurs, in this case until a
collision with the red ball. At this point, the collision will have to be resolved via [the
ball-ball interaction equations]({{ site.url
}}/2020/04/24/psim-theory/#section-ii-ball-ball-interactions).  This will set both the blue and red
balls into motion, the trajectories of which will be defined by equations of motion that will remain
valid up until the next event. Hence, being able to calculate the time until events is essential and
forms the basis of the continuous event-based evolution.

Let's calculate the time of collision $\tau$ for Figure 1. If we assume that the blue ball _rolls_
towards the red ball, then its trajectory is defined by [the rolling equations of motion]({{
site.url }}/2020/04/24/psim-theory/#--case-3-rolling):

$$
\vec{r}^{(i)}(t) = 
\begin{bmatrix}
    r_{0x} + v_0 \cos(\phi) \, t - \frac{1}{2} \mu_r g \cos(\phi) \, t^2 \\
    r_{0y} + v_0 \sin(\phi) \, t - \frac{1}{2} \mu_r g \sin(\phi) \, t^2 \\
    0
\end{bmatrix}
\notag
$$

where $\vec{r}^{(i)}(t)$ is the position of the blue ball at some time $t$. If we adopt the coordinate system in Figure 2:

FIXME

Then $\phi = r _{0y} = r _{0x} = 0$, and the form of $\vec{r}^{(i)}(t)$ reduces significantly to

$$
\vec{r}^{(i)}(t) = 
\begin{bmatrix}
    v_0 \, t - \frac{1}{2} \mu_r g \, t^2 \\
    0 \\
    0
\end{bmatrix}
\label{red_blue_1}
$$

Let $\tau$ be the collision time. By looking at Figure 2, its clear that the collision
occurs when the blue ball has the coordinates

$$
\vec{r}^{(i)}(\tau) = 
\begin{bmatrix}
    D - 2R \\
    0 \\
    0
\end{bmatrix}
\label{red_blue_2}
$$

Plugging Eq. $\eqref{red_blue_1}$ into the LHS of Eq. $\eqref{red_blue_2}$ yields the following
equality at the moment of collision.

$$
2R - D + v_0 \, \tau - \frac{1}{2} \mu_r g \, \tau^2 = 0
\notag
$$

Finding the collision time $\tau$ is as simple as finding the roots to this polynomial equation. The
roots are

$$
\tau = \frac{v \pm \sqrt{v^2 - 2 \mu_r g \, (D - 2 R)}}{\mu_r g}
\label{roots_example}
$$

The root that is positive, real, and smallest defines the collision time. For example, if the
following numbers are plugged into Eq. $\eqref{roots_example}$,

$$
D = 28 \, \text{cm} \\
R = 2.8 \, \text{cm} \\
v_0 = 30 \, \text{cm/s} \\
g = 9.8 \, \text{m/s}^2 \\
\mu_r = 0.01
\notag
$$

the roots are $\tau = 0.87 \text{s}, \, 5.25 \text{s}$, so the collision time is $\tau = 0.87
\text{s}$.

This calculation assumed a specific geometry in which one ball was rolling and one ball was
stationary, so is too specific to be broadly useful.

The collision occurs when the distance $\lvert \vec{d}(t) \rvert$ between the
center of masses of the two balls is $2R$, where $R$ is the radius of the ball. Mathematically,

$$
\lvert \vec{d_{ij}}(\tau) \rvert = \lvert \vec{r}^{(i)}(\tau) - \vec{r}^{(j)}(\tau) \rvert = 2R
\label{ball_collision}
$$

where $\vec{r}^{(i)}(\tau)$ is the position of the blue ball and $\vec{r}^{(j)}(\tau)$ is the
position of the red ball. The form of $\vec{r}^{(i)}(\tau)$ and $\vec{r}^{(j)}(\tau)$ will depend on
the whether the balls are stationary, spinning, rolling, spinning, or airborne. Fortunately, we have
equations of motion for each of these scenarios, each of which can be cast in the following form:

$$
\vec{r}^{(i)}(t) = 
\begin{bmatrix}
    a_x^{(i)} t^2 + b_x^{(i)} t + c_x^{(i)} \\
    a_y^{(i)} t^2 + b_y^{(i)} t + c_y^{(i)} \\
    a_z^{(i)} t^2 + b_z^{(i)} t + c_z^{(i)}
\end{bmatrix}
\label{quad_r}
$$

Each component can be expressed as a quadratic equation with respect to time (though in many cases
the $a$ and $b$ coefficients are 0). For the sake of the example, let's assume the blue ball _rolls_
up until the moment it collides with the red ball. Then the coefficients in Eq. $\eqref{quad_r}$ are

$$
a_x^{(i)} = - \frac{1}{2} \mu_r g \cos(\phi^{(i)})
\notag
$$

$$
a_y^{(i)} = - \frac{1}{2} \mu_r g \sin(\phi^{(i)})
\notag
$$

$$
a_z^{(i)} = 0
\notag
$$

$$
b_x^{(i)} = v_0^{(i)} \cos(\phi^{(i)})
\notag
$$

$$
b_y^{(i)} = v_0^{(i)} \sin(\phi^{(i)})
\notag
$$

$$
b_z^{(i)} = 0
\notag
$$

$$
c_x^{(i)} = r_{0x}^{(i)}
\notag
$$

$$
c_y^{(i)} = r_{0y}^{(i)}
\notag
$$

$$
c_z^{(i)} = 0
\notag
$$

which was determined by looking at the [the rolling equations of motion]({{ site.url
}}/2020/04/24/psim-theory/#--case-3-rolling). Similarly, the red ball is stationary, so looking at
[the stationary equations of motion]({{ site.url }}/2020/04/24/psim-theory/#--case-1-stationary)
yields the following coefficients:

$$
a_x^{(j)} = 0
\notag
$$

$$
a_y^{(j)} = 0
\notag
$$

$$
a_z^{(j)} = 0
\notag
$$

$$
b_x^{(j)} = 0
\notag
$$

$$
b_y^{(j)} = 0
\notag
$$

$$
b_z^{(j)} = 0
\notag
$$

$$
c_x^{(j)} = r_{0x}^{(j)}
\notag
$$

$$
c_y^{(j)} = r_{0y}^{(j)}
\notag
$$

$$
c_z^{(j)} = 0
\notag
$$

Regardless of the particulars, the critical point is that a ball's trajectory is in a sense defined
by these 9 coefficients. To determine if two balls collide, we can formulate the distance vector
$\vec{d}(t)$ from Eq. $\eqref{ball_collision}$ in terms of these 18 coefficients (2 balls, 9
coefficients each):

$$
\vec{d_{ij}}(t) = 
\begin{bmatrix}
    A_x t^2 + B_x t + C_x \\
    A_y t^2 + B_y t + C_y \\
    A_z t^2 + B_z t + C_z \\
\end{bmatrix}
\label{diff_vec}
$$

where

$$
A_x = a_x^{(j)} - a_x^{(i)}
\notag
$$

$$
A_y = a_y^{(j)} - a_y^{(i)}
\notag
$$

$$
A_z = a_z^{(j)} - a_z^{(i)}
\notag
$$

$$
B_x = b_x^{(j)} - b_x^{(i)}
\notag
$$

$$
B_y = b_y^{(j)} - b_y^{(i)}
\notag
$$

$$
B_z = b_z^{(j)} - b_z^{(i)}
\notag
$$

$$
C_x = c_x^{(j)} - c_x^{(i)}
\notag
$$

$$
C_y = c_y^{(j)} - c_y^{(i)}
\notag
$$

$$
C_z = c_z^{(j)} - c_z^{(i)}
\notag
$$

Plugging Eq. $\eqref{diff_vec}$ into Eq. $\eqref{ball_collision}$ yields an equation whose roots
describe the time until two arbitrarily balls collide:

$$
(A_x^2 + A_y^2 + A_z^2) \, t^4 + \\
(2 A_x B_x + 2 A_y B_y + 2 A_z B_z) \, t^3 + \\
(B_x^2 + B_y^2 + B_z^2 + 2 A_x C_x + 2 A_y C_y + 2 A_z C_z) \, t^2 + \\
(2 B_x C_x + 2 B_y C_y + 2 B_z C_z) \, t + \\
C_x^2 + C_y^2 + C_z^2 - 4 R^2 = 0
\label{poly}
$$

It's beauty parallels Euler's $e^{i \pi} + 1 = 0$, don't you think?



One of the ground-breaking papers has been the work of Leckie and Greenspan entitled [An Event-Based
Pool Physics Simulator](https://link.springer.com/chapter/10.1007/11922155_19). A free pre-print of
this publication is available
[here](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.89.4627&rep=rep1&type=pdf).  This is
a pretty groundbreaking paper, because they develop an evolution algorithm that avoids discrete time
integration, the most common way in which many-body systems through time.  To contextualize their
evolution algorithm, I should first talk about what they avoid doing: time integration.

## Can we learn anything from the ivory tower? (answer: yes)

## Discrete time evolution





















Surprisingly, there is a lot of academical research surrouding realistic pool simulators. More often
than not, the introduction sections of these papers go like this: "developing physics engines are a
necessary precursor for creating robots that can play pool", or "game theory for pool is really
interesting, and developing a pool AI demands a realistic engine". The hundreds of thousands of
dollars spent unknowingly by government agenices has clearly been worth the effort:

{% include youtube_embed.html id="4ArBw9kEMMw" %}

Through this line of inquiry, I basically figured out there are two types of evolution algorithms:
discrete time evolution and continus event-based integration

One of the ground-breaking papers has been the work of Leckie and Greenspan entitled [An Event-Based
Pool Physics Simulator](https://link.springer.com/chapter/10.1007/11922155_19). A free pre-print of
this publication is available
[here](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.89.4627&rep=rep1&type=pdf).  This is
a pretty groundbreaking paper, because they develop an evolution algorithm that avoids discrete time
integration, the most common way in which many-body systems through time.  To contextualize their
evolution algorithm, I should first talk about what they avoid doing: time integration.

### Continuous Event-based Simulation

Even with adaptive time stepping, there is going to be wasted computation. So ideally, you'd want to
avoid it altogether. In the example of the colliding balls, what if we could predict when the
collision happens by using knowledge of their positions and velocities? After all, it looks plainly
obvious that they are going to collide, so why waste our time advancing with so many time steps?
Let's add some variables to the picture and solve for $t$!

FIXME

$R$ is the ball radii, $v$ is the speed of the ball, and $d$ is the distance they are from collision
the collision state. If we assume that the Ball A moves with constant velocity, the time until
collision is quiter simply $\tau = d/v$.

This has some serious advantages over time integration. First, it is computationally much more
efficient. It was just one instance of arithmetic: $d/v$. Second, it is not subject to
discretization error. In the discrete time evolution method above, the collision is detected
_after_ it happened since the collision is detected by seeing if the balls are intersecting. But if
they are intersecting, they already collided! This is what I'm calling discretization error. In
contrast, there is no error in $d/v$, save for floating point error.

This is actually a huge deal from the perspective of simulation, but it requires mathematical
formulas for the positions of the bodies as a function of time, and in most multi-body systems, this
is too much to ask. For example, the system of 3 planets exhibiting gravitational forces on one
another has no analytical mathematical formula for the positions as a function of time. Look at how
complex the solution becomes:

FIXME (embed and hyperlink goes to wiki)


#### The algorithm is essentially this

In the above case, discrete numerical integration is a necessity. So is a necessity for pool physics
too? Well, unlike the 3-body gravitational problem which exhibit forces on each other even at a
distance, balls only interact with each other during extremely brief collisions (OK fine, pool balls
also exhibit gravitational forces on each other at a distance, but you're just being pedantic).
Other than during these brief moments, the trajectories of the balls have closed-form equations that
describe their positions, velocities, and spins. So this doesn't solve the problem entirely, but I
can at least accurately simulate the evolution of a pool shot from $t=0$ up to the first collision
without any time integration because I have analytical forms of the trajectories as a function of
time! Then I could apply some well-trodden physics to resolve the
collision, and then evolve the state of all balls until the _next_ collision. Essentially, if you
can solve when a collision happens, you can evolve all balls up to that point in time, solve the
collision's physics by updating the states of the ball(s) involved in the collision, and then
advance time to the next collision. Rinse and repeat.

That's pretty good news, but it is still unknown how to calculate when the first collision occurs.
The solution employed by Leckie and Greenspan is to calculate all possible collision times and take
the one that occurs in the minimal amount of time. When I say all, I mean all.  Since the
trajectories of each ball are known as a function of time (they are quadratic with respect to time
because of the deceleration from the cloth), the collision time between each pair of balls can be
calculated from a fourth order polynomial with respect to time. The roots of this polynomial are the
time needed for the balls to collide. As we know, most balls will not collide--a typical shot will
have maybe 1 or 5 collisions.  The absence of a collision manifests mathematically as negative or
imaginary values to the roots of the fourth order polynomial. So if you have $15$ balls, that means
you have $105$ collision pairs to check, and most of these will not collide (yielding negative or
imaginary values). Yet a subset of these ball-pairs _will_ yield positive real values.  If a
ball-pair yields a non-negative real value, it means that if no other balls or cushions were to "get
in the way" of the collision, the balls would collide in a finite amount
of time. By picking the
one with a smallest postive and real-valued solution to the quartic polynomial, we ensure by
definition that this is the first collision that occurs.

With this time value in hand, we advance the trajectories of _all_ balls up to that point in time,
at which point a collision is occuring, i.e. 2 balls or a ball and a rail are touching. Then, we
apply well-trodden physics that explains the outgoing states of the balls as a result of the
collision (which we assume is instantaneous). After updating the states of the involved balls, we
rinse and repeat: We find the next event, advance the states of all balls up to that time by using
the analytical expressions we have, resolve the physics of the collision, and so on and so forth.

Here is my sketch of the algorithm:

FIXME

## Continuous Event-based simulation is da way man

After doing my resarch, I realized I have _got_ to do a continuous event-based approach. Leckie and
Greenspan give a very rough complexity analysis as to why this is far superior to discrete numerical
integration. For discrete numerical integration, the number of operations is on the order of

$N (61 n - n^2) / 2$

where $n$ is the number of balls, and $N$ is the number of time steps. OK well writing this down
now, I see this is clearly quite a garbage expression because the number of operations grows
negative with large values of $n$. But the important part is this: time complexity scales linearly
with the number of time steps, i.e. accuracy. But assuming it works for small values of $n$, simulating 3 balls
for 1 second using a very coarse time step of 1 millisecond yields $87,000$ required computations.
In contrast, their derived time complexity expression for their continuous event-based approach is

$(645 n - 19 n^2) / 2$

Which yields only 882 operations. More critically, the complexity depends _only_ on the number of
balls.

The bottomline is this: after reading this paper, I decided this project was going to offer
continuous event-based simulations or it wasn't going to offer anything.



